{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "import pymc as pm\n",
    "from pymc.Matplot import plot as mcplot\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "from bson.objectid import ObjectId\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_limit(distribution):\n",
    "    val = distribution.random()\n",
    "    while val > 1 or val < 0:\n",
    "        val = distribution.random()\n",
    "    return val\n",
    "\n",
    "class grader(object):\n",
    "    def __init__(self, name,bias_mean,bias_tau):\n",
    "        self.name = name\n",
    "        self.handins = list()\n",
    "        self.bias_mean = bias_mean\n",
    "        self.bias_tau = bias_tau\n",
    "        \n",
    "    def add_handin(self, handin):\n",
    "        self.handins.append(handin)\n",
    "                \n",
    "    def grade_handins(self):\n",
    "        for handin in self.handins:\n",
    "            B = pm.Normal('B_generator',self.bias_mean,self.bias_tau)\n",
    "            handin.add_gradeing(self,B.random())\n",
    "\n",
    "class handin:\n",
    "    def __init__(self,title,owner,true_value,precision):\n",
    "        self.title = title\n",
    "        self.owner = owner\n",
    "        self.gradeings = dict()\n",
    "        self.graders = list()\n",
    "        self.true_val = true_value\n",
    "        self.precision = precision\n",
    "    \n",
    "    def add_grader(self,grader):\n",
    "        self.graders.append(grader)\n",
    "    \n",
    "    def add_gradeing(self,grader,bias):\n",
    "        obs = pm.Normal('obs_generator',self.true_val+bias,self.precision)\n",
    "        self.gradeings[grader.name] = random_limit(obs)\n",
    "        \n",
    "        \n",
    "class assignment(object):\n",
    "    \n",
    "    def __init__(self, handins_input, graders_input):\n",
    "        self.handins = dict()\n",
    "        self.graders = dict()\n",
    "        for handin in handins_input:\n",
    "            self.handins[handin.title] = handin\n",
    "        for grader in graders_input:\n",
    "            self.graders[grader.name] = grader\n",
    "    \n",
    "    def add_handin(self, handin):\n",
    "        self.handing[handin.title] = handin\n",
    "        \n",
    "    def add_grader(self, grader):\n",
    "        self.graders[grader.title] = grader\n",
    "    \n",
    "    def find_ungraded_handin(self, grader):\n",
    "        \n",
    "        # sort the handins by the one with the least\n",
    "        sorted_l = sorted(self.handins.values(),key=lambda x: len(x.graders))\n",
    "        #i = int(random.uniform(0,len(sorted_l)))\n",
    "        i = 0\n",
    "        handin = sorted_l[i]\n",
    "        while handin in grader.handins or (handin.owner.name == grader.name):\n",
    "        #while(handin.owner.name == grader.name):\n",
    "            i += 1\n",
    "            #i = int(random.uniform(0,len(sorted_l)))\n",
    "            handin = sorted_l[i]\n",
    "        return handin\n",
    "            \n",
    "    def grade_handins(self,n_handins):\n",
    "        # Distribute handins\n",
    "        for i in xrange(0,n_handins):\n",
    "            for grader in self.graders.itervalues():\n",
    "                h = self.find_ungraded_handin(grader)\n",
    "                h.add_grader(g)\n",
    "                grader.add_handin(h)\n",
    "                \n",
    "        # grade handins\n",
    "        for grader in self.graders.itervalues():\n",
    "            grader.grade_handins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(graders, handins):\n",
    "    T_mu = pm.Normal('T_mu_generator',0.5,25)\n",
    "    T_tau = pm.Gamma('T_tau_generator',10,0.1)\n",
    "    B_mu = pm.Normal('B_mu_generator',0,100)\n",
    "    B_tau = pm.Gamma('B_tau_generator',50,0.1)\n",
    "\n",
    "    handins_data = list()\n",
    "    graders_data = list()\n",
    "\n",
    "    for i in xrange(0,graders):\n",
    "        g = grader('grader_%i' % i,B_mu.random(),B_tau.random())\n",
    "        t_mu = random_limit(T_mu)\n",
    "        h = handin('handin_%i' % i, g, t_mu, T_tau.random())\n",
    "        graders_data.append(g)\n",
    "        handins_data.append(h)\n",
    "\n",
    "    assignment_data = assignment(handins_data,graders_data)\n",
    "    assignment_data.grade_handins(handins)\n",
    "    return assignment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_data_2(assignments, graders, handins):\n",
    "    T_mu = pm.Normal('T_mu_generator', 0.5, 25)\n",
    "    T_tau = pm.Gamma('T_tau_generator', 10, 0.1)\n",
    "    B_mu = pm.Normal('B_mu_generator', 0, 100)\n",
    "    B_tau = pm.Gamma('B_tau_generator', 50, 0.1)\n",
    "\n",
    "    handins_data = list()\n",
    "    graders_data = list()\n",
    "    for i in xrange(0, graders):\n",
    "        g = grader('grader_%i' % i, B_mu.random(), B_tau.random())\n",
    "        graders_data.append(g)\n",
    "\n",
    "    for a in xrange(0, assignments):\n",
    "\n",
    "        handins_data_e = list()\n",
    "        grader_min = graders * a\n",
    "        grader_max = grader_min + graders\n",
    "        for i in xrange(grader_min, grader_max):\n",
    "            t_mu = random_limit(T_mu)\n",
    "            h = handin('handin_%i' % i, graders_data[i-grader_min], t_mu, T_tau.random())\n",
    "            handins_data.append(h)\n",
    "\n",
    "    assignment_data = assignment(handins_data, graders_data)\n",
    "    assignment_data.grade_handins(handins)\n",
    "\n",
    "    return assignment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.assignment at 0x12c41e450>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_data_2(2,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Model(data):\n",
    "    N_H = len(data)\n",
    "    \n",
    "    # Bias\n",
    "    T_tau = dict()\n",
    "    T_mu = dict()\n",
    "    B_mu = dict()\n",
    "    B_tau = dict()\n",
    "    O = list()\n",
    "\n",
    "    for h in range(0, N_H):\n",
    "        h_id = data[h].title\n",
    "        scores = data[h].gradeings.items()\n",
    "        \n",
    "        N_G = len(scores)\n",
    "        T_mu[h_id] = pm.Normal('T_mu_%s' % str(h_id),0.5,25)\n",
    "        T_tau[h_id] = pm.Gamma('T_tau_%s' % str(h_id),10,0.1)\n",
    "        \n",
    "        for g in range(0, N_G):\n",
    "            (g_id,val) = scores[g]\n",
    "            \n",
    "            if g_id not in B_mu:\n",
    "                B_mu[g_id] = pm.Normal('B_mu_%s' % str(g_id),0,100)\n",
    "            if g_id not in B_tau:\n",
    "                B_tau[g_id] = pm.Gamma('B_tau_%s' % str(g_id), 50, 0.1)\n",
    "                \n",
    "            O.append(pm.Normal('O_%(h)i_%(g)i' % {'h': h, 'g':g}, mu = T_mu[h_id] + B_mu[g_id], tau=T_tau[h_id] + B_tau[g_id], observed=True, value=val))\n",
    "               \n",
    "    collection = [pm.Container(T_mu),\n",
    "                  pm.Container(T_tau),\n",
    "                  pm.Container(B_mu),\n",
    "                  pm.Container(B_tau),\n",
    "                  pm.Container(O)]\n",
    "    \n",
    "    model = pm.Model(collection)\n",
    "#    map_ = pm.MAP(model)\n",
    "#    map_.fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_model_map(model,samples):\n",
    "    map_ = pm.MAP(model)\n",
    "    map_.fit()\n",
    "    mcmc = pm.MCMC(model)\n",
    "    mcmc.sample(samples)\n",
    "    return mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_model_no_map(model, samples, burn):\n",
    "    mcmc = pm.MCMC(model)\n",
    "    mcmc.sample(samples,burn=burn)\n",
    "    return mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mcmc(model_,values):\n",
    "    return model_(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_bias(assignment,mcmc,f):\n",
    "    bias = list()\n",
    "    for g in assignment.graders.keys():\n",
    "        value = 0\n",
    "        if f == 'var':\n",
    "            value = np.mean(mcmc.trace('B_tau_%s' % str(g))[:])\n",
    "        elif f == 'mean':\n",
    "            value = np.mean(mcmc.trace('B_mu_%s' % str(g))[:])\n",
    "        bias.append((value,g))\n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_T(assignment,mcmc,f):\n",
    "    T = list()\n",
    "    for h in assignment.handins.keys():\n",
    "        value = 0\n",
    "        if f == 'var':\n",
    "            value = np.mean(mcmc.trace('T_tau_%s' % str(h))[:])\n",
    "        elif f == 'mean':\n",
    "            value = np.mean(mcmc.trace('T_mu_%s' % str(h))[:])\n",
    "        T.append((value,h))\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_MSE(assignment_data,mcmc_handins,find, func='mean'):\n",
    "    found = find(assignment_data, mcmc_handins, func)\n",
    "    \n",
    "    # Generate dict of the found values in each run for each grader\n",
    "    compared = defaultdict(list)\n",
    "    collected = list()\n",
    "    collected = found[:]\n",
    "    \n",
    "    for (value, _id) in collected:\n",
    "        compared[_id].append(value)\n",
    "\n",
    "    sorted_list = list()\n",
    "    if find.func_name == \"find_bias\":\n",
    "        for _id, g in assignment_data.graders.iteritems():\n",
    "            if func == \"mean\":\n",
    "                sorted_list.append((_id,g.bias_mean))\n",
    "            else:\n",
    "                sorted_list.append((_id,g.bias_tau))\n",
    "    else:\n",
    "        for _id, h in assignment_data.handins.iteritems():\n",
    "            if func == \"mean\":\n",
    "                sorted_list.append((_id,h.true_val))\n",
    "            else:\n",
    "                sorted_list.append((_id,h.precision))\n",
    "            \n",
    "    sorted_list.sort(key=lambda x: x[1])\n",
    "\n",
    "#    ax = plt.subplot(111)\n",
    "    \n",
    "    labels = list()\n",
    "    true_values = list()\n",
    "    score_values = list()\n",
    "    mean_score_values = list()\n",
    "    MS_val = list()\n",
    "    y = xrange(0,len(sorted_list))\n",
    "    for (_id, value) in sorted_list:\n",
    "#        if find.func_name != \"find_bias\" and func == \"mean\":\n",
    "#            mean_score = np.mean(assignment_data.handins[_id].gradeings.values())\n",
    "#            mean_score_values.append(mean_score)\n",
    "        \n",
    "        MS_val.append(np.mean(compared[_id]))\n",
    "        score_values.append(compared[_id])\n",
    "        true_values.append(value)\n",
    "        labels.append(_id)\n",
    "    \n",
    "#    MSE_T = 0.0\n",
    "    MSE_M = sum(map(lambda x : (float(x[1]) - float(x[0])) ** 2,zip(true_values,MS_val))) / len(true_values)\n",
    "#    print MSE_M\n",
    "#    if find.func_name != \"find_bias\" and func == \"mean\":\n",
    "#        MSE_T = sum(map(lambda x : (float(x[1]) - float(x[0])) ** 2,zip(true_values,mean_score_values))) / len(true_values)\n",
    "#        print MSE_T\n",
    "#    box_text = \"\"\n",
    "#    if find.func_name != \"find_bias\" and func == \"mean\":\n",
    "#    box_text = 'MSE model: %(h)f\\nMSE graded: %(g)f' % {'h': MSE_M, 'g':MSE_T}\n",
    "#    else:\n",
    "    return MSE_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First test is with 20 graders and 10 grading per graders\n",
    "The model with no MAP will have 10000 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data\n",
      "CPU times: user 189 ms, sys: 11.5 ms, total: 200 ms\n",
      "Wall time: 196 ms\n",
      "Building model\n",
      "CPU times: user 967 ms, sys: 15.1 ms, total: 982 ms\n",
      "Wall time: 995 ms\n",
      "Executing model with no MAP\n",
      " [-----------------100%-----------------] 10000 of 10000 complete in 222.1 secCPU times: user 3min 35s, sys: 1.75 s, total: 3min 37s\n",
      "Wall time: 3min 43s\n",
      "Executing model with MAP\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 44.2 secCPU times: user 1min 27s, sys: 755 ms, total: 1min 28s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "print \"Generating data\"\n",
    "%time data = generate_data(20,10)\n",
    "print \"Building model\"\n",
    "%time mcmc = build_mcmc(Model,data.handins.values())\n",
    "print \"Executing model with no MAP\"\n",
    "%time result_no_map = execute_model_no_map(mcmc,10000,2500)\n",
    "print \"Executing model with MAP\"\n",
    "%time result_map = execute_model_map(mcmc,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No MAP used: 0.00163957206108\n",
      "MAP used: 0.00172477477269\n"
     ]
    }
   ],
   "source": [
    "print \"No MAP used: \" + str(find_MSE(data,result_no_map,find_bias))\n",
    "print \"MAP used: \" + str(find_MSE(data,result_map,find_bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First test is with 100 graders and 5 grading per graders\n",
    "The model with no MAP will have 10000 sample and 2500 burn in\n",
    "Modle with MAP will only have 2000 samples and no burn in as it is not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data\n",
      "CPU times: user 466 ms, sys: 10.6 ms, total: 477 ms\n",
      "Wall time: 486 ms\n",
      "Building model\n",
      "CPU times: user 1.6 s, sys: 61 ms, total: 1.66 s\n",
      "Wall time: 1.84 s\n",
      "Executing model with no MAP\n",
      " [-----------------100%-----------------] 10000 of 10000 complete in 706.3 secCPU times: user 11min 33s, sys: 4.76 s, total: 11min 38s\n",
      "Wall time: 11min 49s\n",
      "Executing model with MAP\n",
      " [-----------------100%-----------------] 2001 of 2000 complete in 146.0 secCPU times: user 17min 29s, sys: 6.88 s, total: 17min 36s\n",
      "Wall time: 17min 52s\n"
     ]
    }
   ],
   "source": [
    "print \"Generating data\"\n",
    "%time data = generate_data(100,5)\n",
    "print \"Building model\"\n",
    "%time mcmc = build_mcmc(Model,data.handins.values())\n",
    "print \"Executing model with no MAP\"\n",
    "%time result_no_map = execute_model_no_map(mcmc,10000,2500)\n",
    "print \"Executing model with MAP\"\n",
    "%time result_map = execute_model_map(mcmc,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No MAP used: 0.00324896490478\n",
      "MAP used: 0.00348308582633\n"
     ]
    }
   ],
   "source": [
    "print \"No MAP used: \" + str(find_MSE(data,result_no_map,find_bias))\n",
    "print \"MAP used: \" + str(find_MSE(data,result_map,find_bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First test is with 200 graders and 5 grading per graders\n",
    "The model with no MAP will have 10000 sample and 2500 burn in\n",
    "Modle with MAP will only have 2000 samples and no burn in as it is not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data\n",
      "CPU times: user 952 ms, sys: 16.6 ms, total: 968 ms\n",
      "Wall time: 987 ms\n",
      "Building model\n",
      "CPU times: user 2.49 s, sys: 88.7 ms, total: 2.58 s\n",
      "Wall time: 2.64 s\n"
     ]
    }
   ],
   "source": [
    "print \"Generating data\"\n",
    "%time data = generate_data(200,5)\n",
    "print \"Building model\"\n",
    "%time mcmc = build_mcmc(Model,data.handins.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing model with no MAP\n",
      " [-----------------100%-----------------] 10000 of 10000 complete in 1433.5 secCPU times: user 23min 31s, sys: 8.96 s, total: 23min 40s\n",
      "Wall time: 23min 59s\n"
     ]
    }
   ],
   "source": [
    "print \"Executing model with no MAP\"\n",
    "%time result_no_map = execute_model_no_map(mcmc,10000,2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing model with MAP\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 365.6 secCPU times: user 2h 4min 18s, sys: 1min 20s, total: 2h 5min 39s\n",
      "Wall time: 18h 19min 55s\n"
     ]
    }
   ],
   "source": [
    "print \"Executing model with MAP\"\n",
    "%time result_map = execute_model_map(mcmc,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"No MAP used: \" + str(find_MSE(data,result_no_map,find_bias))\n",
    "print \"MAP used: \" + str(find_MSE(data,result_map,find_bias))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
