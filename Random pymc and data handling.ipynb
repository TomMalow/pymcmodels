{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "import pymc as pm\n",
    "from pymc.Matplot import plot\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "from bson.objectid import ObjectId\n",
    "import jsonpickle\n",
    "from scipy.stats import loggamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../Peergrade/peergrade/')\n",
    "from application.model import data_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = list()\n",
    "for i in range(0,1000):\n",
    "    data.append(np.random.lognormal(mean=0,sigma=1/1000.0))\n",
    "plt.hist(data, bins=25, histtype=\"stepfilled\", normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B_mu = pm.Normal('B_mu_generator',0,1000)\n",
    "data = list()\n",
    "for i in range(0,1000):\n",
    "    data.append(B_mu.random())\n",
    "plt.hist(data, bins=25, histtype=\"stepfilled\", normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pm.skew_normal_like([0.2,0.6,0.5],0.5,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B_mu = pm.Normal('B_mu_generator',0,500)\n",
    "data = list()\n",
    "for i in range(0,1000):\n",
    "    data.append(B_mu.random())\n",
    "plt.hist(data, bins=25, histtype=\"stepfilled\", normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B_tau = pm.Beta('B_tau_generator',2,1.5)\n",
    "data = list()\n",
    "for i in range(0,1000):\n",
    "    data.append(B_tau.random())\n",
    "plt.hist(data, bins=25, histtype=\"stepfilled\", normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loggamma.rvs(50,scale=1/0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = list()\n",
    "for i in range(0,1000):\n",
    "    data.append(loggamma.rvs(50,scale=1/0.1))\n",
    "plt.hist(data, bins=25, histtype=\"stepfilled\", normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B_tau = pm.Gamma('B_tau_generator',50,0.1)\n",
    "data = list()\n",
    "for i in range(0,1000):\n",
    "    data.append(B_tau.random())\n",
    "plt.hist(data, bins=25, histtype=\"stepfilled\", normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B_tau = pm.Gamma('B_tau_generator',50,0.1)\n",
    "data = list()\n",
    "for i in range(0,1000):\n",
    "    B_val = B_tau.random()\n",
    "    B = pm.Normal('B_generator',0,B_val)\n",
    "    data.append(B.random())\n",
    "plt.hist(data, bins=25, histtype=\"stepfilled\", normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B_tau = pm.Gamma('B_tau_generator',50,0.1)\n",
    "B = pm.Normal('B_generator',0,B_tau)\n",
    "data = list()\n",
    "for i in range(0,1000):\n",
    "    data.append(B.random())\n",
    "plt.hist(data, bins=25, histtype=\"stepfilled\", normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B = pm.Normal('B_generator',0,500)\n",
    "data = list()\n",
    "for i in range(0,1000):\n",
    "    B_val = B_tau.random()\n",
    "    B = pm.Normal('B_generator',0,B_val)\n",
    "    data.append(B.random())\n",
    "plt.hist(data, bins=25, histtype=\"stepfilled\", normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NormalGamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B_tau = pm.Gamma('B_tau_generator',50,0.1)\n",
    "data_mu = list()\n",
    "data_tau = list()\n",
    "for i in range(0,1000):\n",
    "    b_tau = B_tau.random()\n",
    "    \n",
    "    data_tau.append(b_tau)\n",
    "    B_mu = pm.Normal('B_mu_generator',0, 1*b_tau)\n",
    "    data_mu.append(B_mu.random())\n",
    "plt.subplot(211)\n",
    "plt.title('Mu')\n",
    "plt.hist(data_mu, bins=25, histtype=\"stepfilled\", normed=True)\n",
    "plt.subplot(212)\n",
    "plt.title('Tau')\n",
    "plt.hist(data_tau, bins=25, histtype=\"stepfilled\", normed=True)\n",
    "print 1/np.var(data_mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformating data and seralizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Question(object):\n",
    "    def __init__(self,_id,_type, assignment, text, max_grade_value):\n",
    "        self._id = _id\n",
    "        self._type = _type\n",
    "        self.assignment = assignment\n",
    "        self.text = text\n",
    "        self.max_grade_value = max_grade_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Answer(object):\n",
    "    def __init__(self, _id, grading, question, flagged):\n",
    "        self._id = _id\n",
    "        self.grading = grading\n",
    "        self.question = question\n",
    "        self.flagged = flagged\n",
    "        \n",
    "    def add_text_answere(self, text):\n",
    "        self.text = text\n",
    "    def add_value_answere(self, graded_value, normalized):\n",
    "        self.grade_value = graded_value\n",
    "        self.normalized = normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Grading(object):\n",
    "    def __init__(self, _id, grader, handin, answeres, assignment, feedback_grade):\n",
    "        self._id = _id\n",
    "        self.grader = grader\n",
    "        self.answeres = answeres # list of asnwer ids\n",
    "        self.handin = handin\n",
    "        self.assignment = assignment\n",
    "        self.feedback_grade = feedback_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class User(object):\n",
    "    def __init__(self, _id, name, graded_handins):\n",
    "        self._id = _id\n",
    "        self.name = name\n",
    "        self.graded_handins = graded_handins # list of handins ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Handin(object):\n",
    "    def __init__(self,_id, assignment, owners, gradings):\n",
    "        self._id = _id\n",
    "        self.assignment = assignment\n",
    "        self.owners = owners # list of grader ids\n",
    "        self.gradings = gradings #list of grading ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Assignment(object):\n",
    "    def __init__(self, _id, title, questions, handins):\n",
    "        self._id = _id\n",
    "        self.title = title\n",
    "        self.questions = questions # list of question ids\n",
    "        self.handins = handins # list of handins ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Course(object):\n",
    "    def __init__(self, _id, title, assignments, participants):\n",
    "        self._id = _id\n",
    "        self.title = title\n",
    "        self.assignments = assignments # list of assignments ids\n",
    "        self.participants = participants # list of graders ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.heroku_rnwkcq9r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the ids of the relevant objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assignments_i = list()\n",
    "graders_i = list()\n",
    "questions_i = list() # assignment id as key\n",
    "assignment_question_i = defaultdict(list)\n",
    "questions_assignment_i = dict() # assignment id as key\n",
    "handins_i = defaultdict(list) # assignment id as key\n",
    "gradings_i = defaultdict(list) # handin id as key \n",
    "grading_handin_i = dict() # grading id as key\n",
    "answeres_i = defaultdict(list) # gradings id as key\n",
    "\n",
    "course = db.course.find_one({'_id': ObjectId(\"55d9cb9ea6fb8f00080da4a1\")})\n",
    "\n",
    "for gradr_i in course['students']:\n",
    "    for g_d in db.user.find({'_id': gradr_i}):\n",
    "        graders_i.append(g_d)\n",
    "\n",
    "for ass_d in db.assignment.find({'course': course['_id']}):\n",
    "    ass_i = str(ass_d['_id'])\n",
    "    assignments_i.append(ass_d)\n",
    "    # questions \n",
    "    for sec_i in ass_d['sections']:\n",
    "        sec_d = db.question_section.find_one({'_id': sec_i})\n",
    "        for q_i in sec_d['questions']:\n",
    "            for q_d in db.question.find({'_id': q_i}):\n",
    "                questions_i.append(q_d)\n",
    "                questions_assignment_i[str(q_i)] = ass_i\n",
    "                assignment_question_i[str(ass_i)].append(str(q_i))\n",
    "                \n",
    "    # handins\n",
    "    for han_d in db.handin.find({'assignment': ObjectId(ass_i)}):\n",
    "        han_i = str(han_d['_id'])\n",
    "        handins_i[ass_i].append(han_d)\n",
    "        #gradings\n",
    "        for grad_d in db.report_grade.find({'handin': ObjectId(han_i), 'state': 'ANSWERED'}):\n",
    "            grad_i = str(grad_d['_id'])\n",
    "            gradings_i[han_i].append(grad_d)\n",
    "            grading_handin_i[grad_i] = han_i\n",
    "            #answeres\n",
    "            for answer_d in db.answer.find({'report_grade': ObjectId(grad_i)}):\n",
    "                answeres_i[grad_i].append(answer_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the found ids to populate the previous defined objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attr(entries,key):\n",
    "    return map(lambda x: x[key],entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_max_value(question_id):\n",
    "    question = db.question.find_one({'_id': ObjectId(question_id)})\n",
    "    if question['question_type'] == \"boolean\":\n",
    "        return 1\n",
    "    elif question[\"question_type\"] == \"numerical\":\n",
    "        if 'numericalAnswers' in question:\n",
    "            max_value = max(map(int,question['numericalAnswers'].keys()))\n",
    "            return max_value\n",
    "        else:\n",
    "            return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_value_normalized(answer_id):\n",
    "    answer = db.answer.find_one({'_id': answer_id})\n",
    "    q_id = answer['question']\n",
    "    if 'numerical_answer' in answer:\n",
    "        return answer['numerical_answer'] / float(question_max_value(q_id))\n",
    "    elif 'boolean_answer' in answer:\n",
    "        return answer['boolean_answer'] / float(question_max_value(q_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_value(answer_id):\n",
    "    '''returns the normalized value of an answere'''\n",
    "    answer = db.answer.find_one({'_id': answer_id})\n",
    "    q_id = answer['question']\n",
    "    if 'numerical_answer' in answer:\n",
    "        return answer['numerical_answer']\n",
    "    elif 'boolean_answer' in answer:\n",
    "        return answer['boolean_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graders_gradings(grader_id):\n",
    "    gradings = list()\n",
    "    for g in db.report_grade.find({'giver': grader_id}):\n",
    "        gradings.append(g)\n",
    "    return gradings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question objects: dependent on assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(r\"BigDataFormattedData/questions.txt\", \"w\") as o_file:\n",
    "    for q in questions_i:\n",
    "        _id = str(q['_id'])\n",
    "        q_obj = Question(_id,q['question_type'],questions_assignment_i[_id],q['text'],question_max_value(_id))\n",
    "        q_enc = jsonpickle.encode(q_obj,unpicklable=False)\n",
    "        o_file.write(q_enc + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer objects: dependent on question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(r\"BigDataFormattedData/answers.txt\", \"w\") as o_file:\n",
    "    for g, ans in answeres_i.iteritems():\n",
    "        for a in ans:\n",
    "            _id = a['_id']\n",
    "            flagged = False\n",
    "            if 'flagged' in a:\n",
    "                flagged = a['flagged'] \n",
    "            a_obj = Answer(str(_id), g, str(a['question']),flagged)\n",
    "            if 'text_answer'in a:\n",
    "                a_obj.add_text_answere(a['text_answer'])\n",
    "            else:\n",
    "                a_obj.add_value_answere(answer_value(_id),answer_value_normalized(_id))\n",
    "            a_enc = jsonpickle.encode(a_obj,unpicklable=False)\n",
    "            o_file.write(a_enc + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grading objects: dependant on grader, answeres and handin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(r\"BigDataFormattedData/gradings.txt\", \"w\") as o_file:\n",
    "    for h, gradings in gradings_i.iteritems():\n",
    "        for g in gradings:\n",
    "            _id = str(g['_id'])\n",
    "            answeres = map(lambda x:str(x),attr(answeres_i[_id],'_id'))\n",
    "            feedback = None\n",
    "            if 'feedback_grade' in g:\n",
    "                feedback = g['feedback_grade']\n",
    "            g_obj = Grading(_id, str(g['giver']), str(g['handin']), answeres, str(g['assignment']),feedback)\n",
    "            g_enc = jsonpickle.encode(g_obj,unpicklable=False)\n",
    "            o_file.write(g_enc + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grader object: dependent on handins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(r\"BigDataFormattedData/users.txt\", \"w\") as o_file:\n",
    "        for g in graders_i:\n",
    "            _id = str(g['_id'])\n",
    "            g_obj = User(_id, g['name'],map(str,(attr(graders_gradings(g['_id']),'_id'))))\n",
    "            g_enc = jsonpickle.encode(g_obj,unpicklable=False)\n",
    "            o_file.write(g_enc + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handin objects: dependent on graders and gradings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(r\"BigDataFormattedData/handins.txt\", \"w\") as o_file:\n",
    "    for a, handins in handins_i.iteritems():\n",
    "        for h in handins:\n",
    "            _id = str(h['_id'])\n",
    "            owners = map(lambda x:str(x),h['students'])\n",
    "            gradings = map(lambda x:str(x),attr(gradings_i[_id],'_id'))\n",
    "            h_obj = Handin(_id, a, owners, gradings)\n",
    "            h_enc = jsonpickle.encode(h_obj,unpicklable=False)\n",
    "            o_file.write(h_enc + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment objects: depndent on questions and handins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(r\"BigDataFormattedData/assignments.txt\", \"w\") as o_file:\n",
    "    for a in assignments_i:\n",
    "        _id = str(a['_id'])\n",
    "        a_obj = Assignment(_id, a['title'], assignment_question_i[_id], map(str,attr(handins_i[_id],'_id')))\n",
    "        a_enc = jsonpickle.encode(a_obj,unpicklable=False)\n",
    "        o_file.write(a_enc + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course object: dependent on graders and assignemnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(r\"BigDataFormattedData/courses.txt\", \"w\") as o_file:\n",
    "    _id = str(course['_id'])\n",
    "    assignments = map(str,attr(assignments_i,'_id'))\n",
    "    c_obj = Course(_id, course['title'], assignments, map(str,course['students']))\n",
    "    c_enc = jsonpickle.encode(c_obj,unpicklable=False)\n",
    "    o_file.write(c_enc + \"\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.heroku_rnwkcq9r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finds the reported score for each handins in an assignment\n",
    "# returns a list containing the score of each handin\n",
    "def course_handins_id(course_id):\n",
    "    handins_reports = list()\n",
    "    assignments = db.assignment.find({'course': course_id})\n",
    "    for assignment in assignments:\n",
    "        \n",
    "        handins = db.handin.find({'assignment': assignment['_id']})\n",
    "        for handin in handins:\n",
    "            handins_reports.append(handin['_id'])\n",
    "    return handins_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(course_handins_id(ObjectId(\"55d9cb9ea6fb8f00080da4a1\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "from matplotlib.pylab import * \n",
    "\n",
    "\n",
    "n=10000\n",
    "rho=.99 #correlation\n",
    "#Means\n",
    "m1 = 10\n",
    "m2 = 20\n",
    "#Standard deviations\n",
    "s1 = 1\n",
    "s2 = 1\n",
    "#Initialize vectors\n",
    "x=zeros(n, float)\n",
    "y=zeros(n, float)\n",
    "sd=sqrt(1-rho**2)\n",
    "# the core of the method: sample recursively from two normal distributions\n",
    "# The mean for the current sample, is updated at each step.\n",
    "for i in range(1,n):\n",
    "  x[i] = normal(m1+rho*(y[i-1]-m2)/s2,s1*sd)\n",
    "  y[i] = normal(m2+rho*(x[i-1]-m1)/s1,s2*sd)\n",
    "\n",
    "scatter(x,y,marker='d',c='r')\n",
    "xlabel('x')\n",
    "ylabel('y')\n",
    "grid()\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_log_pdf(x,u,t):\n",
    "    return -0.5*t*(x-u)**2+np.log(t)-np.log(np.sqrt(2.0*math.pi))\n",
    "\n",
    "def gamma_log_pdf(x,a,b):\n",
    "    return a*np.log(b)-np.log(math.gamma(a))+(a-1.0)*np.log(x)-b*x\n",
    "\n",
    "def norm_gamma_log_pdf(u,t,ga,la,a,b):\n",
    "    return a*np.log(b)+np.log(np.sqrt(la))-np.log(math.gamma(a))-np.log(np.sqrt(2.0*math.pi))+(a-1)*np.log(t)-np.log(b*t)-0.5*t*la*(u-ga)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEPCAYAAAC6Kkg/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a928fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import *\n",
    "from matplotlib.pylab import * \n",
    "\n",
    "\n",
    "n=10000\n",
    "\n",
    "#Means\n",
    "m1 = 10.0\n",
    "#Standard deviations\n",
    "s1 = 0.5\n",
    "#Initialize vectors\n",
    "x=zeros(n, float)\n",
    "y=zeros(n, float)\n",
    "x[0] = 0.0\n",
    "log_x = norm_log_pdf(0,m1,s1)\n",
    "# the core of the method: sample recursively from two normal distributions\n",
    "# The mean for the current sample, is updated at each step.\n",
    "i = 1\n",
    "while i < n:\n",
    "    # Sample u_h and t_h\n",
    "  \n",
    "    # Propose new candidates\n",
    "    x_c = np.random.normal(x[i-1],0.1)\n",
    "    #draw from gamma\n",
    "    p_ = norm_log_pdf(x_c,m1,s1)\n",
    "    alpha = min(1.0,p_-log_x)\n",
    "    if np.log(np.random.random()) <= alpha:\n",
    "        x[i] = x_c\n",
    "        log_x = p_\n",
    "        i = i + 1\n",
    "\n",
    "plt.hist(x,bins=30)\n",
    "scatter(x,y,marker='d',c='r')\n",
    "xlabel('x')\n",
    "ylabel('y')\n",
    "grid()\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0]), matrix([[ 0.9,  0.1],\n",
       "         [ 0.5,  0.5]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_0 = np.array([1,0])\n",
    "T = np.matrix('0.9,0.1;0.5,0.5')\n",
    "s_0, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.9,  0.1]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_1 = np.dot(s_0,T)\n",
    "s_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.86,  0.14]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_2 = np.dot(s_1,T)\n",
    "s_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.86,  0.14]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_2 = np.dot(s_0,T**2)\n",
    "s_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "def gibbs_sampler(alpha,delta,gamma,y,t):\n",
    "    #initialize beta\n",
    "    beta=1\n",
    "\n",
    "    num_iter=1000\n",
    "\n",
    "    beta_draws=[]\n",
    "    lambda_draws=[]\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        #sample lambda given other lambdas and beta\n",
    "        lambdas=lambda_update(alpha,beta,y,t)\n",
    "\n",
    "        #record sample\n",
    "        lambda_draws.append(lambdas)\n",
    "\n",
    "        #sample beta given lambda samples\n",
    "        beta=beta_update(alpha,gamma,delta,lambdas,y)\n",
    "\n",
    "        #record sample\n",
    "        beta_draws.append(beta)\n",
    "\n",
    "    pl.plot(beta_draws)\n",
    "    pl.show()\n",
    "\n",
    "def lambda_update(alpha,beta,y,t):\n",
    "\n",
    "    new_alpha=[(x+alpha) for x in y]\n",
    "    new_beta=[1.0/(a+beta) for a in t]#Changed here\n",
    "\n",
    "    #sample from this distribution 10 times\n",
    "    samples=random.gamma(new_alpha,new_beta)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def beta_update(alpha,gamma,delta,lambdas,y):\n",
    "    #get sample\n",
    "    sample=random.gi(len(y)*alpha+gamma, \n",
    "                        1.0 / (delta+sum(lambdas)))#Changed here\n",
    "    return sample\n",
    "\n",
    "y=[5,1,5,14,3,19,1,1,4,22]\n",
    "t=[94,16,63,126,5,31,1,1,2,10]\n",
    "\n",
    "alpha=1.8\n",
    "gamma=0.01\n",
    "delta=1\n",
    "\n",
    "gibbs_sampler(alpha,delta,gamma,y,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "questions = list()\n",
    "grade_p_s = list()\n",
    "grade_p_h = list()\n",
    "students = list()\n",
    "handins = list()\n",
    "\n",
    "assignments_d = data_model.Assignment.objects()\n",
    "for assignment in assignments_d:\n",
    "    v = len(data_model.Handin.objects(assignment=assignment))\n",
    "    if v != 0:\n",
    "        handins.append(v)\n",
    "    v = len(assignment.course.students)\n",
    "    if v != 0:\n",
    "        students.append(len(assignment.course.students))\n",
    "    if assignment.grades_per_student != 0:\n",
    "        grade_p_s.append(assignment.grades_per_student)\n",
    "    if assignment.grades_per_handin != 23:\n",
    "        grade_p_h.append(assignment.grades_per_handin)\n",
    "    n_questions = 0\n",
    "    for section in assignment.sections:\n",
    "        for question in section.questions:\n",
    "            if question.question_type == \"text\":\n",
    "                n_questions = n_questions + 1\n",
    "    questions.append(n_questions)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions\n",
      "Mean: 2.505348 Median: 2.000000 Max: 22 Min: 0\n",
      "Students\n",
      "Mean: 54.801802 Median: 22.000000 Max: 322 Min: 1\n",
      "Hand-ins\n",
      "Mean: 18.335505 Median: 9.000000 Max: 253 Min: 1\n",
      "Grades per student\n",
      "Mean: 2.716714 Median: 3.000000 Max: 6 Min: 1\n",
      "Grades per handin\n",
      "Mean: 4.005362 Median: 4.000000 Max: 11 Min: 1\n"
     ]
    }
   ],
   "source": [
    "print \"Questions\"\n",
    "print \"Mean: %f Median: %f Max: %i Min: %i\" % (np.mean(questions), np.median(questions), max(questions), min(questions))\n",
    "print \"Students\"\n",
    "print \"Mean: %f Median: %f Max: %i Min: %i\" % (np.mean(students), np.median(students), max(students), min(students))\n",
    "print \"Hand-ins\"\n",
    "print \"Mean: %f Median: %f Max: %i Min: %i\" % (np.mean(handins), np.median(handins), max(handins), min(handins))\n",
    "print \"Grades per student\"\n",
    "print \"Mean: %f Median: %f Max: %i Min: %i\" % (np.mean(grade_p_s), np.median(grade_p_s), max(grade_p_s), min(grade_p_s))\n",
    "print \"Grades per handin\"\n",
    "print \"Mean: %f Median: %f Max: %i Min: %i\" % (np.mean(grade_p_h), np.median(grade_p_h), max(grade_p_h), min(grade_p_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 11,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_p_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 236.,   57.,   22.,   21.,    8.,    0.,    6.,   14.,    1.,    9.]),\n",
       " array([   0. ,   32.2,   64.4,   96.6,  128.8,  161. ,  193.2,  225.4,\n",
       "         257.6,  289.8,  322. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSZIkSZKGx/8DyNQQO+eWx3QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114817190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
