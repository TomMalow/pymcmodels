{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "import pymc3 as pm\n",
    "from pymc3 import traceplot\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.heroku_rnwkcq9r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_text(question_id):\n",
    "    question = db.question.find_one({'_id': question_id})\n",
    "    return question['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_max_value(question_id):\n",
    "    question = db.question.find_one({'_id': question_id})\n",
    "    if question['question_type'] == \"boolean\":\n",
    "        return 1\n",
    "    elif question[\"question_type\"] == \"numerical\":\n",
    "        if 'numericalAnswers' in question:\n",
    "            max_value = max(map(int,question['numericalAnswers'].keys()))\n",
    "            return max_value\n",
    "        else:\n",
    "            return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_value(answer_id):\n",
    "    answer = db.answer.find_one({'_id': answer_id})\n",
    "    q_id = answer['question']\n",
    "    if 'numerical_answer' in answer:\n",
    "        return answer['numerical_answer'] / float(question_max_value(q_id))\n",
    "    elif 'boolean_answer' in answer:\n",
    "        return answer['boolean_answer'] / float(question_max_value(q_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_with_score(answer_id):\n",
    "    answer = db.answer.find_one({'_id': answer_id})\n",
    "    return 'text_answer' not in answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_handin_grader(handin_id,grader_id):\n",
    "    # find all answers to the hand in of the grader and average it out\n",
    "    report_grade = db.report_grade.find_one({'handin': handin_id, 'giver': grader_id})\n",
    "    answers = db.answer.find({'report_grade': report_grade['_id'] })\n",
    "    handin_acc = 0.0\n",
    "    for answer in answers:\n",
    "        if answer_with_score(answer['_id']):\n",
    "            handin_acc = handin_acc + answer_value(answer['_id'])\n",
    "    return handin_acc / float(answers.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_handin_list(handin_id):\n",
    "    scores = list()\n",
    "    report_grades = db.report_grade.find({'handin': handin_id, 'state': 'ANSWERED'})\n",
    "    for report_grade in report_grades:\n",
    "        scores.append((score_handin_grader(handin_id,report_grade['giver']),report_grade['giver']))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finds the reported score for each handins in an assignment\n",
    "# returns a list containing the score of each handin\n",
    "def assignment_handins(assignment_id):\n",
    "    handins_reports = list()\n",
    "    handins = db.handin.find({'assignment': assignment_id})\n",
    "    for handin in handins:\n",
    "        handins_reports.append((score_handin_list(handin['_id']),handin['_id']))\n",
    "    return handins_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grader_ids(assignment_id):\n",
    "    graders = set()\n",
    "    report_grades = db.report_grade.find({'assignment':assignment_id})\n",
    "    for report_grade in report_grades:\n",
    "        graders.add(report_grade['giver'])\n",
    "    return list(graders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grader_name(grader_id):\n",
    "    grader = db.user.find_one({'_id': grader_id})\n",
    "    return grader['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def course_handins(course_id):\n",
    "    handins = list()\n",
    "    assignments = db.assignment.find({'course':course_id})\n",
    "    for assignment in assignments:\n",
    "        handins.extend(assignment_handins(assignment['_id']))\n",
    "    return handins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_bias(assignment_id,mcmc,f):\n",
    "    bias_abs = list()\n",
    "    for g in grader_ids(assignment_id):\n",
    "        try:     \n",
    "            bias_mean = f(mcmc.trace('B_%s' % str(g))[:])\n",
    "            name = str(g)\n",
    "            bias_abs.append((abs(bias_mean),name))\n",
    "        except:\n",
    "            print \"error\"\n",
    "            pass\n",
    "    return bias_abs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [(0.2726495726495726, ObjectId('55e4330ded7a0c0009f0d9d9')),\n",
    " (0.6410256410256411, ObjectId('55f2d136d8786100099ff332')),\n",
    " (0.5128205128205128, ObjectId('55db3833edf3950009412132')),\n",
    " (0.46153846153846156, ObjectId('55e59e8336cc7d00092c414a')),\n",
    " (0.6410256410256411, ObjectId('55d9cb9ea6fb8f00080da473')),\n",
    " (0.6153846153846154, ObjectId('55db3833edf395000941213d')),\n",
    " (0.4871794871794871, ObjectId('56056a8689c698000f9c29bd')),\n",
    " (0.9957264957264957, ObjectId('55db3832edf395000941211a'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = map(lambda x: x[0],data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pm.Model() as s_model:\n",
    "    N = len(data)\n",
    "\n",
    "    # True score\n",
    "    T_mu = pm.Uniform('T_mu',0,1)\n",
    "    T = pm.Normal('T', mu=T_mu, tau=100, testval = np.mean(data))\n",
    "\n",
    "    # Bias\n",
    "    B = list()\n",
    "    O = list()\n",
    "\n",
    "    for i in range(0, N):\n",
    "        B.append(pm.Normal('B_%i' % i, mu=0, tau=100, testval=0))\n",
    "        O.append(pm.Normal('O_%i' % i, mu = T + B[i], tau=100, observed=data[i]))\n",
    "\n",
    "    distr = [T_mu, T]\n",
    "    distr.extend(B)\n",
    "    distr.extend(O)\n",
    "    step = pm.NUTS(distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with s_model:\n",
    "    start = pm.find_MAP()\n",
    "    mcmc = pm.sample(2000, step, start=start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = mcmc[\"T\"][:]\n",
    "plt.hist(T, histtype=\"step\", normed=True, alpha=0.5, bins=30,\n",
    "         label=\"T\", color=\"#348ABD\")\n",
    "B0 = mcmc[\"B_1\"][:]\n",
    "plt.hist(B0, histtype=\"step\", normed=True, alpha=0.5, bins=30,\n",
    "         label=\"B0\")\n",
    "plt.xlim(-0.5,1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"The mean value of the observed data:\"\n",
    "print np.mean(data)\n",
    "print \"The expected value of the normal distribution of T, the true score:\"\n",
    "print np.mean(T)\n",
    "print \"The expected value of the normal distribution of the bias of the first grader B0:\"\n",
    "print np.mean(B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_handin = assignment_handins(ObjectId(\"55f277cff3bd61000a2112d4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_abs_1 = find_bias(ObjectId(\"55f277cff3bd61000a2112d4\"), mcmc_handin, np.mean)\n",
    "bias_abs_2 = find_bias(ObjectId(\"55f277cff3bd61000a2112d4\"), mcmc_handin2, np.mean)\n",
    "bias_abs_1.sort()\n",
    "bias_abs_2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compared_12 = list()\n",
    "for idx, (value, _id) in enumerate(bias_abs_1):\n",
    "    for item in enumerate(bias_abs_2):\n",
    "        if item[1][1] == _id:\n",
    "            compared_12.append((_id ,idx, item[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "\n",
    "largest_diff = 0\n",
    "largest_diff_id = \"\"\n",
    "\n",
    "for idx, (_id, bias1,bias2) in enumerate(compared_12):\n",
    "    if bias1 > bias2:\n",
    "        plt.plot([idx,idx],[bias1,bias2], color='g')\n",
    "    else:\n",
    "        plt.plot([idx,idx],[bias1,bias2], color='r')\n",
    "    if abs(bias1-bias2) > largest_diff:\n",
    "        largest_diff = abs(bias1-bias2)\n",
    "        largest_diff_id = _id\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0,\n",
    "                 box.width * 3, box.height])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = course_handins(ObjectId(\"55d9cb9ea6fb8f00080da4a1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def handin_model(model, data):\n",
    "    with pm.Model() as model:\n",
    "        N_H = len(data)\n",
    "\n",
    "        # Bias\n",
    "        T = dict()\n",
    "        B = dict()\n",
    "        O = list()\n",
    "\n",
    "        for h in range(0, N_H):\n",
    "            (scores,h_id) = data[h]\n",
    "            N_G = len(scores)\n",
    "\n",
    "    #        T_temp = pm.Uniform('T_mu_%s' % str(h_id),lower=0,upper=1,testval = np.mean(map(lambda x:x[0],scores)))\n",
    "    #        T_mu.append(T_temp)\n",
    "            T[h_id] = pm.Normal('T_%s' % str(h_id), mu=np.mean(map(lambda x:x[0],scores)), tau=100)\n",
    "\n",
    "            for g in range(0, N_G):\n",
    "                (val,g_id) = scores[g]\n",
    "                if g_id not in B:\n",
    "                    B[g_id] = pm.Normal('B_%s' % str(g_id), mu=0, tau=100)\n",
    "                O.append(pm.Normal('O_%(h)i_%(g)i' % {'h': h, 'g':g}, mu = T[h_id] + B[g_id], tau=100, observed=val))\n",
    "\n",
    "        distr = list()\n",
    "        distr.extend(T.values())\n",
    "        distr.extend(B.values())\n",
    "        distr.extend(O[:])\n",
    "        step = pm.NUTS(distr)\n",
    "        return step\n",
    "        \n",
    "def execute_model(model,step):\n",
    "    with model:\n",
    "        start = pm.find_MAP()\n",
    "        mcmc = pm.sample(2000, step, start=start)\n",
    "        return mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_model = pm.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step = handin_model(c_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmc1 = execute_model(c_model,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcmc2 = execute_model(c_model,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
